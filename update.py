import pandas as pd
import os
import time
import sys
import socket
from pytdx.hq import TdxHq_API

# --- æ ¸å¿ƒé…ç½® ---
DATA_DIR = 'stock_data'
PROGRESS_DIR = 'results_data_update'
PROGRESS_FILE = os.path.join(PROGRESS_DIR, 'progress.txt')
STOCK_LIST_FILE = 'åˆ—è¡¨.txt'
BATCH_SIZE = 200  # æ¯æ‰¹å¤„ç†200åªï¼Œå¹³è¡¡é€Ÿåº¦ä¸ç¨³å®šæ€§

# æ•´åˆä½ æä¾›çš„åæ³°èŠ‚ç‚¹åŠå¸¸ç”¨ç¨³å®šèŠ‚ç‚¹
TDX_SERVERS = [
    ('101.227.73.20', 7709),   # åæ³°è¯åˆ¸(ä¸Šæµ·ç”µä¿¡) - æ¨èæµ·å¤–ä¼˜å…ˆ
    ('101.227.77.254', 7709),  # åæ³°è¯åˆ¸(ä¸Šæµ·ç”µä¿¡äºŒ)
    ('122.192.35.44', 7709),   # åæ³°è¯åˆ¸(å—äº¬è”é€š)
    ('221.231.141.60', 7709),  # åæ³°è¯åˆ¸(å—äº¬ç”µä¿¡)
    ('59.173.18.140', 7709),   # åæ³°è¯åˆ¸(æ­¦æ±‰ç”µä¿¡)
    ('14.215.128.18', 7709),   # åæ³°è¯åˆ¸(æ·±åœ³ç”µä¿¡)
    ('183.60.224.178', 7709),  # å¹¿å·ç”µä¿¡
    ('119.147.212.81', 7709),  # æ‹›å•†è¯åˆ¸
    ('218.75.126.9', 7709),    # æ­å·ç”µä¿¡
]

def get_best_server():
    """è‡ªåŠ¨åŒ–å¯»æ‰¾å»¶è¿Ÿæœ€ä½çš„æœåŠ¡å™¨"""
    best_ip = None
    min_latency = float('inf')
    print("ğŸš€ æ­£åœ¨æ‰«ææœ€å¿«é€šè¾¾ä¿¡æœåŠ¡å™¨...")
    for ip, port in TDX_SERVERS:
        start_time = time.time()
        try:
            with socket.create_connection((ip, port), timeout=1.5) as conn:
                latency = time.time() - start_time
                print(f"ğŸ“¡ {ip} | å“åº”: {latency:.3f}s")
                if latency < min_latency:
                    min_latency = latency
                    best_ip = ip
        except:
            print(f"âŒ {ip} | è¿æ¥è¶…æ—¶")
    return best_ip

def fetch_tdx_data(code, api):
    """æŠ“å–Kçº¿å¹¶å°è¯•è‡ªåŠ¨è®¡ç®—æ¢æ‰‹ç‡"""
    market = 1 if code.startswith('6') else 0
    try:
        # 1. è·å–æ—¥Kçº¿ (å«æ˜¨æ”¶ç”¨äºè®¡ç®—)
        data = api.get_security_bars(9, market, code, 0, 2)
        if not data or len(data) < 1: return pd.DataFrame()
        
        # 2. è·å–è´¢åŠ¡ä¿¡æ¯ï¼ˆç”¨äºè®¡ç®—æ¢æ‰‹ç‡ï¼šæˆäº¤é‡ / æµé€šè‚¡æœ¬ï¼‰
        # æ³¨ï¼šPytdxçš„æˆäº¤é‡å•ä½æ˜¯æ‰‹(100è‚¡)ï¼Œè´¢åŠ¡æ•°æ®çš„liutonggubenå•ä½é€šå¸¸ä¹Ÿæ˜¯è‚¡
        finance = api.get_finance_info(market, code)
        liutong = finance.get('liutongguben', 0) if finance else 0
        
        df_raw = pd.DataFrame(data)
        curr = df_raw.iloc[-1]
        prev_close = df_raw.iloc[0]['close'] if len(df_raw) > 1 else curr['close']
        
        # è®¡ç®—æ¢æ‰‹ç‡ (æˆäº¤é‡*100 / æµé€šè‚¡æœ¬ * 100%)
        turnover = 0.0
        if liutong > 0:
            turnover = round((curr['vol'] * 100 / liutong) * 100, 2)

        row = {
            'æ—¥æœŸ': pd.to_datetime(curr['datetime']).strftime('%Y-%m-%d'),
            'è‚¡ç¥¨ä»£ç ': code,
            'å¼€ç›˜': float(curr['open']),
            'æ”¶ç›˜': float(curr['close']),
            'æœ€é«˜': float(curr['high']),
            'æœ€ä½': float(curr['low']),
            'æˆäº¤é‡': int(curr['vol']),
            'æˆäº¤é¢': float(curr['amount']),
            'æŒ¯å¹…': round((curr['high'] - curr['low']) / prev_close * 100, 2) if prev_close != 0 else 0,
            'æ¶¨è·Œå¹…': round((curr['close'] - prev_close) / prev_close * 100, 2) if prev_close != 0 else 0,
            'æ¶¨è·Œé¢': round(curr['close'] - prev_close, 2),
            'æ¢æ‰‹ç‡': turnover
        }
        
        res_df = pd.DataFrame([row])
        # ä¸¥æ ¼åŒ¹é…ä½ çš„12åˆ—æ ¼å¼
        cols = ['æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡']
        return res_df[cols]
    except:
        return pd.DataFrame()

def main():
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(PROGRESS_DIR, exist_ok=True)

    # 1. åŠ è½½è‚¡ç¥¨åˆ—è¡¨
    try:
        stock_df = pd.read_csv(STOCK_LIST_FILE, sep='\t')
        stock_df.columns = stock_df.columns.str.strip().str.lower()
        code_col = 'ä»£ç ' if 'ä»£ç ' in stock_df.columns else 'code'
        stock_df[code_col] = stock_df[code_col].astype(str).str.zfill(6)
        # æ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿
        stock_list = stock_df[~stock_df[code_col].str.startswith(('300', '301', '688'))]
        codes = stock_list[code_col].tolist()
    except Exception as e:
        print(f"âŒ è¯»å–åˆ—è¡¨å¤±è´¥: {e}")
        sys.exit(1)

    # 2. æ–­ç‚¹ç»­ä¼ é€»è¾‘
    start_index = 0
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r') as f:
            try: start_index = int(f.read().strip())
            except: start_index = 0

    if start_index >= len(codes):
        print("âœ… æœ¬æ¬¡æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œé‡ç½®è¿›åº¦ç´¢å¼•ã€‚")
        with open(PROGRESS_FILE, 'w') as f: f.write('0')
        sys.exit(0)

    # 3. è¿æ¥æœ€å¿«æœåŠ¡å™¨
    best_ip = get_best_server()
    if not best_ip:
        print("ğŸ”¥ è­¦æŠ¥ï¼šæ²¡æœ‰å¯ç”¨çš„é€šè¾¾ä¿¡æœåŠ¡å™¨ï¼")
        sys.exit(1)

    api = TdxHq_API()
    with api.connect(best_ip, 7709):
        end_index = min(start_index + BATCH_SIZE, len(codes))
        current_batch = codes[start_index:end_index]
        print(f"ğŸ“ˆ æ­£åœ¨å¤„ç†: {start_index} -> {end_index} (æ€»è®¡: {len(codes)})")

        for code in current_batch:
            df_new = fetch_tdx_data(code, api)
            if not df_new.empty:
                file_path = os.path.join(DATA_DIR, f"{code}.csv")
                # æ•°æ®åˆå¹¶ä¸å»é‡
                if os.path.exists(file_path):
                    old_df = pd.read_csv(file_path)
                    old_df['è‚¡ç¥¨ä»£ç '] = old_df['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
                    combined = pd.concat([old_df, df_new]).drop_duplicates(subset=['æ—¥æœŸ'], keep='last')
                    combined.to_csv(file_path, index=False)
                else:
                    df_new.to_csv(file_path, index=False)
                print(f"{code}", end=' ', flush=True)
            # ç¨å¾®é™ä½è¯·æ±‚é¢‘ç‡ï¼Œé˜²æ­¢è¢«å°IP
            time.sleep(0.05)

    # 4. æ›´æ–°è¿›åº¦
    with open(PROGRESS_FILE, 'w') as f:
        f.write(str(end_index))
    
    print(f"\nâœ¨ æ‰¹æ¬¡ {end_index} å¤„ç†å®Œæ¯•ã€‚")
    if end_index < len(codes):
        sys.exit(99) # è§¦å‘ GitHub Actions çš„è‡ªæˆ‘é‡å¯
    else:
        sys.exit(0)

if __name__ == "__main__":
    main()
