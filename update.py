import pandas as pd
import os
import time
import sys
import socket
from pytdx.hq import TdxHq_API

# --- å¸¸é‡é…ç½® ---
DATA_DIR = 'stock_data'
PROGRESS_DIR = 'results_data_update'
PROGRESS_FILE = os.path.join(PROGRESS_DIR, 'progress.txt')
STOCK_LIST_FILE = 'åˆ—è¡¨.txt'
BATCH_SIZE = 300 

# å¤‡é€‰æœåŠ¡å™¨åˆ—è¡¨ (æ¶µç›–æ·±åœ³ã€ä¸Šæµ·ã€æ­¦æ±‰ç­‰æ ¸å¿ƒèŠ‚ç‚¹)
TDX_SERVERS = [
    ('119.147.212.81', 7709),  # æ·±åœ³ä¸»ç«™
    ('115.238.90.165', 7709),  # æµ™æ±Ÿç”µä¿¡
    ('218.75.126.9', 7709),    # æ­å·ç”µä¿¡
    ('124.160.9.155', 7709),   # æµ™æ±Ÿè”é€š
    ('61.153.209.139', 7709),  # å®æ³¢ç”µä¿¡
    ('183.60.224.178', 7709),  # å¹¿å·ç”µä¿¡
]

def get_best_server():
    """éå†æœåŠ¡å™¨åˆ—è¡¨ï¼Œå¯»æ‰¾å“åº”æœ€å¿«çš„èŠ‚ç‚¹"""
    best_ip = None
    min_latency = float('inf')
    
    print("å¼€å§‹æµ‹è¯•é€šè¾¾ä¿¡æœåŠ¡å™¨å»¶è¿Ÿ...")
    for ip, port in TDX_SERVERS:
        start_time = time.time()
        try:
            # è®¾ç½® 2 ç§’è¶…æ—¶ï¼Œé˜²æ­¢åœ¨ Action ç¯å¢ƒä¸­æŒ‚æ­»
            conn = socket.create_connection((ip, port), timeout=2)
            latency = time.time() - start_time
            print(f"ğŸ“¡ {ip}:{port} - å»¶è¿Ÿ: {latency:.3f}s")
            if latency < min_latency:
                min_latency = latency
                best_ip = ip
            conn.close()
        except Exception:
            print(f"âŒ {ip}:{port} - è¿æ¥è¶…æ—¶/å¤±è´¥")
            
    return best_ip

def fetch_tdx_data(code, api):
    """(ä¿æŒåŸæœ‰é€»è¾‘)"""
    market = 1 if code.startswith('6') else 0
    try:
        data = api.get_security_bars(9, market, code, 0, 2)
        if not data or len(data) < 1: return pd.DataFrame()
        
        df_raw = pd.DataFrame(data)
        curr = df_raw.iloc[-1]
        prev_close = df_raw.iloc[0]['close'] if len(df_raw) > 1 else curr['close']
        
        row = {
            'æ—¥æœŸ': pd.to_datetime(curr['datetime']).strftime('%Y-%m-%d'),
            'è‚¡ç¥¨ä»£ç ': code,
            'å¼€ç›˜': float(curr['open']),
            'æ”¶ç›˜': float(curr['close']),
            'æœ€é«˜': float(curr['high']),
            'æœ€ä½': float(curr['low']),
            'æˆäº¤é‡': int(curr['vol']),
            'æˆäº¤é¢': float(curr['amount']),
            'æ¶¨è·Œé¢': round(curr['close'] - prev_close, 2),
            'æ¶¨è·Œå¹…': round((curr['close'] - prev_close) / prev_close * 100, 2) if prev_close != 0 else 0,
            'æŒ¯å¹…': round((curr['high'] - curr['low']) / prev_close * 100, 2) if prev_close != 0 else 0,
            'æ¢æ‰‹ç‡': 0.0 
        }
        res_df = pd.DataFrame([row])
        cols = ['æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡']
        return res_df[cols]
    except:
        return pd.DataFrame()

def main():
    # 1. åŠ è½½è‚¡ç¥¨åˆ—è¡¨
    try:
        stock_df = pd.read_csv(STOCK_LIST_FILE, sep='\t')
        stock_df.columns = stock_df.columns.str.strip().str.lower()
        code_col = 'ä»£ç ' if 'ä»£ç ' in stock_df.columns else 'code'
        stock_df[code_col] = stock_df[code_col].astype(str).str.zfill(6)
        stock_list = stock_df[~stock_df[code_col].str.startswith(('300', '301', '688'))]
        codes = stock_list[code_col].tolist()
    except Exception as e:
        print(f"è¯»å–åˆ—è¡¨å¤±è´¥: {e}")
        sys.exit(1)

    # 2. è¯»å–è¿›åº¦
    start_index = 0
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r') as f:
            try: start_index = int(f.read().strip())
            except: start_index = 0

    if start_index >= len(codes):
        print("æ‰€æœ‰æ•°æ®å·²å®Œæˆï¼Œé‡ç½®è¿›åº¦ã€‚")
        with open(PROGRESS_FILE, 'w') as f: f.write('0')
        sys.exit(0)

    # 3. å¯»æ‰¾æœ€å¿«æœåŠ¡å™¨å¹¶è¿æ¥
    best_server_ip = get_best_server()
    if not best_server_ip:
        print("âŒ æ— æ³•è¿æ¥ä»»ä½•é€šè¾¾ä¿¡æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ GitHub Action ç½‘ç»œç¯å¢ƒã€‚")
        sys.exit(1)

    api = TdxHq_API()
    if not api.connect(best_server_ip, 7709):
        print(f"âŒ å°è¯•è¿æ¥æœ€å¿«æœåŠ¡å™¨ {best_server_ip} å¤±è´¥")
        sys.exit(1)

    # 4. æ‰§è¡Œæ›´æ–° (é€»è¾‘åŒä¸Š)
    end_index = min(start_index + BATCH_SIZE, len(codes))
    current_batch = codes[start_index:end_index]

    for code in current_batch:
        df_new = fetch_tdx_data(code, api)
        if not df_new.empty:
            file_path = os.path.join(DATA_DIR, f"{code}.csv")
            if os.path.exists(file_path):
                old_df = pd.read_csv(file_path)
                old_df['è‚¡ç¥¨ä»£ç '] = old_df['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
                combined = pd.concat([old_df, df_new]).drop_duplicates(subset=['æ—¥æœŸ'], keep='last')
                combined.to_csv(file_path, index=False)
            else:
                df_new.to_csv(file_path, index=False)
            print(f"âˆš {code}", end=' ')
    
    api.disconnect()

    # 5. ä¿å­˜è¿›åº¦ä¸é€€å‡º
    with open(PROGRESS_FILE, 'w') as f: f.write(str(end_index))
    if end_index < len(codes):
        print(f"\nè¿›åº¦: {end_index}/{len(codes)}ï¼Œåˆ†æ‰¹ç»§ç»­...")
        sys.exit(99)
    else:
        print("\næ›´æ–°ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")
        sys.exit(0)

if __name__ == "__main__":
    main()
