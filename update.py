import pandas as pd
import os
import time
import sys
import socket
from pytdx.hq import TdxHq_API

# --- å¸¸é‡é…ç½® ---
DATA_DIR = 'stock_data'
PROGRESS_DIR = 'results_data_update'
PROGRESS_FILE = os.path.join(PROGRESS_DIR, 'progress.txt')
STOCK_LIST_FILE = 'åˆ—è¡¨.txt'
BATCH_SIZE = 100 # GitHubç¯å¢ƒå»ºè®®å…ˆè®¾å°ä¸€ç‚¹ï¼Œç¨³å®šåå†è°ƒå¤§

# å¤‡é€‰æœåŠ¡å™¨åˆ—è¡¨
TDX_SERVERS = [
    ('183.60.224.178', 7709),
    ('115.238.90.165', 7709),
    ('119.147.212.81', 7709),
    ('218.75.126.9', 7709),
]

def get_best_server():
    best_ip = None
    min_latency = float('inf')
    print("å¼€å§‹æµ‹è¯•é€šè¾¾ä¿¡æœåŠ¡å™¨å»¶è¿Ÿ...")
    for ip, port in TDX_SERVERS:
        start_time = time.time()
        try:
            conn = socket.create_connection((ip, port), timeout=2)
            latency = time.time() - start_time
            print(f"ğŸ“¡ {ip}:{port} - å»¶è¿Ÿ: {latency:.3f}s")
            if latency < min_latency:
                min_latency = latency
                best_ip = ip
            conn.close()
        except Exception:
            print(f"âŒ {ip}:{port} - è¿æ¥è¶…æ—¶/å¤±è´¥")
    return best_ip

def fetch_tdx_data(code, api):
    market = 1 if code.startswith('6') else 0
    try:
        # è·å–2æ¡æ•°æ®è®¡ç®—æ¶¨è·Œ
        data = api.get_security_bars(9, market, code, 0, 2)
        if not data or len(data) < 1: return pd.DataFrame()
        
        df_raw = pd.DataFrame(data)
        curr = df_raw.iloc[-1]
        prev_close = df_raw.iloc[0]['close'] if len(df_raw) > 1 else curr['close']
        
        row = {
            'æ—¥æœŸ': pd.to_datetime(curr['datetime']).strftime('%Y-%m-%d'),
            'è‚¡ç¥¨ä»£ç ': code,
            'å¼€ç›˜': float(curr['open']),
            'æ”¶ç›˜': float(curr['close']),
            'æœ€é«˜': float(curr['high']),
            'æœ€ä½': float(curr['low']),
            'æˆäº¤é‡': int(curr['vol']),
            'æˆäº¤é¢': float(curr['amount']),
            'æ¶¨è·Œé¢': round(curr['close'] - prev_close, 2),
            'æ¶¨è·Œå¹…': round((curr['close'] - prev_close) / prev_close * 100, 2) if prev_close != 0 else 0,
            'æŒ¯å¹…': round((curr['high'] - curr['low']) / prev_close * 100, 2) if prev_close != 0 else 0,
            'æ¢æ‰‹ç‡': 0.0 
        }
        res_df = pd.DataFrame([row])
        cols = ['æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡']
        return res_df[cols]
    except:
        return pd.DataFrame()

def main():
    # å¼ºåˆ¶ç¡®ä¿æ‰€æœ‰ç›®å½•å­˜åœ¨ (ä¿®å¤ FileNotFoundError)
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(PROGRESS_DIR, exist_ok=True)

    # 1. åŠ è½½è‚¡ç¥¨åˆ—è¡¨
    try:
        if not os.path.exists(STOCK_LIST_FILE):
            print(f"æ‰¾ä¸åˆ° {STOCK_LIST_FILE}")
            sys.exit(1)
        stock_df = pd.read_csv(STOCK_LIST_FILE, sep='\t')
        stock_df.columns = stock_df.columns.str.strip().str.lower()
        code_col = 'ä»£ç ' if 'ä»£ç ' in stock_df.columns else 'code'
        stock_df[code_col] = stock_df[code_col].astype(str).str.zfill(6)
        stock_list = stock_df[~stock_df[code_col].str.startswith(('300', '301', '688'))]
        codes = stock_list[code_col].tolist()
    except Exception as e:
        print(f"è¯»å–åˆ—è¡¨å¤±è´¥: {e}")
        sys.exit(1)

    # 2. è¯»å–è¿›åº¦
    start_index = 0
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r') as f:
            try:
                line = f.read().strip()
                start_index = int(line) if line else 0
            except: start_index = 0

    if start_index >= len(codes):
        print("æ‰€æœ‰æ•°æ®å·²å®Œæˆï¼Œé‡ç½®è¿›åº¦ã€‚")
        with open(PROGRESS_FILE, 'w') as f: f.write('0')
        sys.exit(0)

    # 3. å¯»æ‰¾å¹¶è¿æ¥æœåŠ¡å™¨
    best_server_ip = get_best_server()
    if not best_server_ip:
        print("âŒ æ— æ³•è¿æ¥ä»»ä½•æœåŠ¡å™¨")
        sys.exit(1)

    api = TdxHq_API()
    if not api.connect(best_server_ip, 7709):
        sys.exit(1)

    # 4. æ‰§è¡Œæ›´æ–°
    end_index = min(start_index + BATCH_SIZE, len(codes))
    current_batch = codes[start_index:end_index]
    print(f"æ­£åœ¨å¤„ç†æ‰¹æ¬¡: {start_index} -> {end_index}")

    for code in current_batch:
        df_new = fetch_tdx_data(code, api)
        if not df_new.empty:
            file_path = os.path.join(DATA_DIR, f"{code}.csv")
            if os.path.exists(file_path):
                old_df = pd.read_csv(file_path)
                old_df['è‚¡ç¥¨ä»£ç '] = old_df['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
                combined = pd.concat([old_df, df_new]).drop_duplicates(subset=['æ—¥æœŸ'], keep='last')
                combined.to_csv(file_path, index=False)
            else:
                df_new.to_csv(file_path, index=False)
            print(f"âˆš {code}", end=' ', flush=True) # å¢åŠ  flush=True å®æ—¶æ‰“å°
    
    api.disconnect()

    # 5. ä¿å­˜è¿›åº¦ (å·²åœ¨ main å¼€å§‹å¤„ç¡®ä¿ç›®å½•å­˜åœ¨)
    with open(PROGRESS_FILE, 'w') as f:
        f.write(str(end_index))
    
    print(f"\nå½“å‰æ‰¹æ¬¡ä¿å­˜æˆåŠŸã€‚")
    if end_index < len(codes):
        sys.exit(99)
    else:
        sys.exit(0)

if __name__ == "__main__":
    main()
